{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Credit Data Preprocessing  <a class='anchor' id='toc'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I. [Import Data & Libraries](#idl)\n",
    "#### II. [Data Cleaning](#dc)\n",
    "#### III. [Simple Model CV](#smcv)\n",
    "#### VI. [Stacking](#s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Import Data & Libraries <a class=\"anchor\" id=\"idl\"></a>\n",
    "**[Back to top](#toc)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sysux\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modeling\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble.forest import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Data Viz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Change directory\n",
    "import os\n",
    "directory = 'C:/Users/sysux/Desktop/Home Credit/home-credit-default-risk'\n",
    "os.chdir(directory)\n",
    "\n",
    "# Ignore warnings\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import main table\n",
    "train = pd.read_csv('encoded_train_if.csv')\n",
    "test= pd.read_csv('encoded_test_if.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store and remove the label\n",
    "train_label = train['TARGET']\n",
    "train = train.drop('TARGET', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['Unnamed: 0'], axis=1)\n",
    "test = test.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>EXT_SOURCE_1</th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>...</th>\n",
       "      <th>installment_NUM_INSTALMENT_NUMBER_mean</th>\n",
       "      <th>installment_AMT_INSTALMENT_mean</th>\n",
       "      <th>installment_AMT_PAYMENT_sum</th>\n",
       "      <th>p_app_AMT_ANNUITY_mean</th>\n",
       "      <th>p_app_AMT_DOWN_PAYMENT_mean</th>\n",
       "      <th>p_app_HOUR_APPR_PROCESS_START_mean</th>\n",
       "      <th>p_app_RATE_DOWN_PAYMENT_mean</th>\n",
       "      <th>p_app_SELLERPLACE_AREA_mean</th>\n",
       "      <th>p_app_SELLERPLACE_AREA_sum</th>\n",
       "      <th>p_app_CNT_PAYMENT_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>0.018801</td>\n",
       "      <td>-9461</td>\n",
       "      <td>-637.0</td>\n",
       "      <td>-3648.0</td>\n",
       "      <td>-2120</td>\n",
       "      <td>0.083037</td>\n",
       "      <td>0.262949</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>11559.247105</td>\n",
       "      <td>219625.695</td>\n",
       "      <td>9251.775</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.0</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>-16765</td>\n",
       "      <td>-1188.0</td>\n",
       "      <td>-1186.0</td>\n",
       "      <td>-291</td>\n",
       "      <td>0.311267</td>\n",
       "      <td>0.622246</td>\n",
       "      <td>...</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>64754.586000</td>\n",
       "      <td>1618864.650</td>\n",
       "      <td>56553.990</td>\n",
       "      <td>3442.50</td>\n",
       "      <td>14.666667</td>\n",
       "      <td>0.050030</td>\n",
       "      <td>533.000000</td>\n",
       "      <td>1599.0</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>-19046</td>\n",
       "      <td>-225.0</td>\n",
       "      <td>-4260.0</td>\n",
       "      <td>-2531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.555912</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7096.155000</td>\n",
       "      <td>21288.465</td>\n",
       "      <td>5357.250</td>\n",
       "      <td>4860.00</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.212008</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>-19005</td>\n",
       "      <td>-3039.0</td>\n",
       "      <td>-9833.0</td>\n",
       "      <td>-2437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650442</td>\n",
       "      <td>...</td>\n",
       "      <td>4.437500</td>\n",
       "      <td>62947.088438</td>\n",
       "      <td>1007153.415</td>\n",
       "      <td>23651.175</td>\n",
       "      <td>34840.17</td>\n",
       "      <td>14.666667</td>\n",
       "      <td>0.163412</td>\n",
       "      <td>894.222222</td>\n",
       "      <td>8048.0</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>-19932</td>\n",
       "      <td>-3038.0</td>\n",
       "      <td>-4311.0</td>\n",
       "      <td>-3458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.322738</td>\n",
       "      <td>...</td>\n",
       "      <td>7.045455</td>\n",
       "      <td>12666.444545</td>\n",
       "      <td>806127.975</td>\n",
       "      <td>12278.805</td>\n",
       "      <td>3390.75</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>0.159516</td>\n",
       "      <td>409.166667</td>\n",
       "      <td>2455.0</td>\n",
       "      <td>20.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  REGION_POPULATION_RELATIVE  \\\n",
       "0          202500.0    406597.5      24700.5                    0.018801   \n",
       "1          270000.0   1293502.5      35698.5                    0.003541   \n",
       "2           67500.0    135000.0       6750.0                    0.010032   \n",
       "3          135000.0    312682.5      29686.5                    0.008019   \n",
       "4          121500.0    513000.0      21865.5                    0.028663   \n",
       "\n",
       "   DAYS_BIRTH  DAYS_EMPLOYED  DAYS_REGISTRATION  DAYS_ID_PUBLISH  \\\n",
       "0       -9461         -637.0            -3648.0            -2120   \n",
       "1      -16765        -1188.0            -1186.0             -291   \n",
       "2      -19046         -225.0            -4260.0            -2531   \n",
       "3      -19005        -3039.0            -9833.0            -2437   \n",
       "4      -19932        -3038.0            -4311.0            -3458   \n",
       "\n",
       "   EXT_SOURCE_1  EXT_SOURCE_2  ...  installment_NUM_INSTALMENT_NUMBER_mean  \\\n",
       "0      0.083037      0.262949  ...                               10.000000   \n",
       "1      0.311267      0.622246  ...                                5.080000   \n",
       "2           NaN      0.555912  ...                                2.000000   \n",
       "3           NaN      0.650442  ...                                4.437500   \n",
       "4           NaN      0.322738  ...                                7.045455   \n",
       "\n",
       "   installment_AMT_INSTALMENT_mean  installment_AMT_PAYMENT_sum  \\\n",
       "0                     11559.247105                   219625.695   \n",
       "1                     64754.586000                  1618864.650   \n",
       "2                      7096.155000                    21288.465   \n",
       "3                     62947.088438                  1007153.415   \n",
       "4                     12666.444545                   806127.975   \n",
       "\n",
       "   p_app_AMT_ANNUITY_mean  p_app_AMT_DOWN_PAYMENT_mean  \\\n",
       "0                9251.775                         0.00   \n",
       "1               56553.990                      3442.50   \n",
       "2                5357.250                      4860.00   \n",
       "3               23651.175                     34840.17   \n",
       "4               12278.805                      3390.75   \n",
       "\n",
       "   p_app_HOUR_APPR_PROCESS_START_mean  p_app_RATE_DOWN_PAYMENT_mean  \\\n",
       "0                            9.000000                      0.000000   \n",
       "1                           14.666667                      0.050030   \n",
       "2                            5.000000                      0.212008   \n",
       "3                           14.666667                      0.163412   \n",
       "4                           12.333333                      0.159516   \n",
       "\n",
       "   p_app_SELLERPLACE_AREA_mean  p_app_SELLERPLACE_AREA_sum  \\\n",
       "0                   500.000000                       500.0   \n",
       "1                   533.000000                      1599.0   \n",
       "2                    30.000000                        30.0   \n",
       "3                   894.222222                      8048.0   \n",
       "4                   409.166667                      2455.0   \n",
       "\n",
       "   p_app_CNT_PAYMENT_mean  \n",
       "0               24.000000  \n",
       "1               10.000000  \n",
       "2                4.000000  \n",
       "3               23.000000  \n",
       "4               20.666667  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set full shape:  (307511, 26)\n",
      "Testing set full shape:  (48744, 26)\n"
     ]
    }
   ],
   "source": [
    "print('Training set full shape: ', train.shape)\n",
    "print('Testing set full shape: ' , test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Data Cleaning <a class=\"anchor\" id=\"dc\"></a>\n",
    "**[Back to top](#toc)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AMT_INCOME_TOTAL                                  0\n",
       "AMT_CREDIT                                        0\n",
       "AMT_ANNUITY                                      12\n",
       "REGION_POPULATION_RELATIVE                        0\n",
       "DAYS_BIRTH                                        0\n",
       "DAYS_EMPLOYED                                 55374\n",
       "DAYS_REGISTRATION                                 0\n",
       "DAYS_ID_PUBLISH                                   0\n",
       "EXT_SOURCE_1                                 173378\n",
       "EXT_SOURCE_2                                    660\n",
       "EXT_SOURCE_3                                  60965\n",
       "DAYS_LAST_PHONE_CHANGE                            1\n",
       "os_NAME_CONTRACT_STATUS_Active_count_norm     18067\n",
       "pos_MONTHS_BALANCE_mean                       18067\n",
       "pos_CNT_INSTALMENT_FUTURE_mean                18091\n",
       "installment_NUM_INSTALMENT_VERSION_mean       15868\n",
       "installment_NUM_INSTALMENT_NUMBER_mean        15868\n",
       "installment_AMT_INSTALMENT_mean               15868\n",
       "installment_AMT_PAYMENT_sum                   15868\n",
       "p_app_AMT_ANNUITY_mean                        16871\n",
       "p_app_AMT_DOWN_PAYMENT_mean                   33906\n",
       "p_app_HOUR_APPR_PROCESS_START_mean            16454\n",
       "p_app_RATE_DOWN_PAYMENT_mean                  33906\n",
       "p_app_SELLERPLACE_AREA_mean                   16454\n",
       "p_app_SELLERPLACE_AREA_sum                    16454\n",
       "p_app_CNT_PAYMENT_mean                        16869\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show NA columns\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute NA value\n",
    "imputer = SimpleImputer(strategy = 'median')\n",
    "imputer.fit(train)\n",
    "train = imputer.transform(train)\n",
    "test = imputer.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Simple Model CV <a class=\"anchor\" id=\"smcv\"></a>\n",
    "**[Back to top](#toc)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the train and test data\n",
    "X_train = train\n",
    "y_train = train_label\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a grid/randomized search cross validation pipleline \n",
    "def search_pipeline(X_train_data, X_test_data, y_train_data, \n",
    "                       model, param_grid, cv=10, scoring_fit=make_scorer(roc_auc_score),\n",
    "                       do_probabilities = False, search_mode = 'GridSearchCV', n_iterations = 0):\n",
    "    fitted_model = None\n",
    "    \n",
    "    if(search_mode == 'GridSearchCV'):\n",
    "        cv = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grid, \n",
    "            cv=cv, \n",
    "            n_jobs=1, \n",
    "            scoring=scoring_fit,\n",
    "            verbose=2\n",
    "        )\n",
    "        fitted_model = cv.fit(X_train_data, y_train_data)\n",
    "\n",
    "    elif (search_mode == 'RandomizedSearchCV'):\n",
    "        cv = RandomizedSearchCV(\n",
    "            estimator=model,\n",
    "            param_distributions=param_grid, \n",
    "            cv=cv,\n",
    "            n_iter=n_iterations,\n",
    "            n_jobs=1, \n",
    "            scoring=scoring_fit,\n",
    "            verbose=2\n",
    "        )\n",
    "        fitted_model = cv.fit(X_train_data, y_train_data)\n",
    "    \n",
    "    \n",
    "    if(fitted_model != None):\n",
    "        if do_probabilities:\n",
    "            pred = fitted_model.predict_proba(X_test_data)\n",
    "        else:\n",
    "            pred = fitted_model.predict(X_test_data)\n",
    "            \n",
    "        return [fitted_model, pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier()\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 600],\n",
    "    'colsample_bytree': [0.7, 0.8],\n",
    "    'max_depth': [15,20,25],\n",
    "    'num_leaves': [50, 100, 200],\n",
    "    'reg_alpha': [1.1, 1.2, 1.3],\n",
    "    'reg_lambda': [1.1, 1.2, 1.3],\n",
    "    'min_split_gain': [0.3, 0.4],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'subsample_freq': [20]\n",
    "}\n",
    "\n",
    "result = search_pipeline(X_train, X_test, y_train, model, \n",
    "                              param_grid, cv=5, scoring_fit=make_scorer(roc_auc_score),\n",
    "                              do_probabilities = True, search_mode = 'RandomizedSearchCV', n_iterations = 5)\n",
    "\n",
    "print(result[0].best_score_)\n",
    "print(result[0].best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier()\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 600],\n",
    "    'max_depth': [15,20,25],\n",
    "}\n",
    "\n",
    "result = search_pipeline(X_train, X_test, y_train, model, \n",
    "                              param_grid, cv=5, scoring_fit=make_scorer(roc_auc_score),\n",
    "                              do_probabilities = True, search_mode = 'RandomizedSearchCV', n_iterations = 2)\n",
    "\n",
    "# Root Mean Squared Error\n",
    "print(result[0].best_score_)\n",
    "print(result[0].best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 600],\n",
    "    'max_depth': [15,20,25],\n",
    "    'max_leaf_nodes': [50, 100, 200]\n",
    "}\n",
    "\n",
    "result = search_pipeline(X_train, X_test, y_train, model, \n",
    "                              param_grid, cv=5, scoring_fit=make_scorer(roc_auc_score),\n",
    "                              do_probabilities = True, search_mode = 'RandomizedSearchCV', n_iterations = 5)\n",
    "\n",
    "print(result[0].best_score_)\n",
    "print(result[0].best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(activation = 'relu',\n",
    "              optimizer = 'Adam'):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(10, activation='relu', kernel_initializer='random_normal', input_dim=X_train_scaled.shape[1]))\n",
    "    model.add(Dense(4, activation='relu', kernel_initializer='random_normal'))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', \n",
    "        optimizer=optimizer, \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "              'epochs':[1,2,3],\n",
    "              'batch_size':[128]\n",
    "              #'epochs' :              [100,150,200],\n",
    "              #'batch_size' :          [32, 128],\n",
    "              #'optimizer' :           ['Adam', 'Nadam'],\n",
    "              #'dropout_rate' :        [0.2, 0.3],\n",
    "              #'activation' :          ['relu', 'elu']\n",
    "             }\n",
    "\n",
    "model = KerasClassifier(build_fn = build_cnn, verbose=0)\n",
    "\n",
    "result = search_pipeline(X_train_scaled, X_test_scaled, y_train, model, \n",
    "                              param_grid, cv=5, scoring_fit=make_scorer(roc_auc_score),\n",
    "                              do_probabilities = True, search_mode = 'GridSearchCV', n_iterations = 5)\n",
    "\n",
    "print(result[0].best_score_)\n",
    "print(result[0].best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Stacking <a class=\"anchor\" id=\"s\"></a>\n",
    "**[Back to top](#toc)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining our estimator, the algorithm to optimize\n",
    "models_to_train = [xgb.XGBClassifier(), lgb.LGBMClassifier(), RandomForestClassifier()]\n",
    "\n",
    "# Defining the hyperparameters to optimize\n",
    "grid_parameters = [\n",
    "    { # XGBoost\n",
    "        'n_estimators': [100, 300, 600],\n",
    "        'max_depth': [15,20,25],\n",
    "    },\n",
    "    { # LightGBM\n",
    "        'n_estimators': [100, 300, 6000],\n",
    "        'learning_rate': [0.12],\n",
    "        'max_depth': [4],\n",
    "        'num_leaves': [10, 20],\n",
    "    }, \n",
    "    { # Random Forest\n",
    "        'max_depth':[3, 5, 10, 13], \n",
    "        'n_estimators':[100, 300, 600],\n",
    "        'max_features':[2, 4, 6, 8, 10]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_preds_scores = []\n",
    "\n",
    "for i, model in enumerate(models_to_train):\n",
    "    params = grid_parameters[i]\n",
    "    \n",
    "    result = search_pipeline(X_train, X_test, y_train, \n",
    "                                 model, params, cv=2)\n",
    "    models_preds_scores.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the result as a baseline\n",
    "for result in models_preds_scores:\n",
    "    print('Model: {0}, Score: {1}'.format(type(result[0].best_estimator_).__name__, roc_auc_score(result[1], y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improve the performance using stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = xgb.XGBClassifier()\n",
    "lgbm = lgb.LGBMClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "lg = LogisticRegression()\n",
    "svr = SVR()\n",
    "\n",
    "stack = StackingCVClassifier(classifiers=(xgboost, lgbm, rf, lg, svr),\n",
    "                            meta_classifier=xgboost, cv=12,\n",
    "                            use_features_in_secondary=True,\n",
    "                            store_train_meta_features=True,\n",
    "                            shuffle=False,\n",
    "                            random_state=42)\n",
    "\n",
    "stack.fit(X_train, y_train)\n",
    "\n",
    "pred = stack.predict(X_test)\n",
    "score = r2_score(y_test, pred)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
